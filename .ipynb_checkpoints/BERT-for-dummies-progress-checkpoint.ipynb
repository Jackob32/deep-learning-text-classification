{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from platform import python_version\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version==3.7.4\n",
      "pandas==0.25.2\n",
      "numpy==1.17.3\n",
      "torch==1.3.1\n",
      "sklearn==0.21.3\n",
      "transformers==2.1.1\n",
      "matplotlib==3.1.1\n"
     ]
    }
   ],
   "source": [
    "print(\"python version==%s\" % python_version())\n",
    "print(\"pandas==%s\" % pd.__version__)\n",
    "print(\"numpy==%s\" % np.__version__)\n",
    "print(\"torch==%s\" % torch.__version__)\n",
    "print(\"sklearn==%s\" % sklearn.__version__)\n",
    "print(\"transformers==%s\" % transformers.__version__)\n",
    "print(\"matplotlib==%s\" % matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6bd6b9d63139>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-6bd6b9d63139>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    loading the ATIS dataset\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " loading the ATIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " loading the ATIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Letâ€™s set the random seed to make the experiment repeatable and shuffle the dataset. Shuffling data serves the purpose of reducing variance and making sure that the model will overfit less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "df = df.sample(frac=1)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Example of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ca72b5b9c688e9e</td>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c03f72fd8f8bf54f</td>\n",
       "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9e5b8e8fc1ff2e84</td>\n",
       "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5332799e706665a6</td>\n",
       "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfa7d8f0b4366680</td>\n",
       "      <td>(and if such phrase exists, it would be provid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  7ca72b5b9c688e9e  Geez, are you forgetful!  We've already discus...      0   \n",
       "1  c03f72fd8f8bf54f  Carioca RFA \\n\\nThanks for your support on my ...      0   \n",
       "2  9e5b8e8fc1ff2e84  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...      0   \n",
       "3  5332799e706665a6  Pseudoscience category? \\n\\nI'm assuming that ...      0   \n",
       "4  dfa7d8f0b4366680  (and if such phrase exists, it would be provid...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Geez, are you forgetful!  We've already discussed why Marx  was  not an anarchist, i.e. he wanted to use a State to mold his 'socialist man.'  Ergo, he is a statist - the opposite of an  anarchist.  I know a guy who says that, when he gets old and his teeth fall out, he'll quit eating meat.  Would you call him a vegetarian?\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "103      1             1        1       0       1              0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "df.iloc[[103]][target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[:1000].reset_index(drop=True)\n",
    "df_val = df[1000:1100].reset_index(drop=True)\n",
    "df_test = df[1100:1300].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id                                       comment_text  \\\n",
      "0    7ca72b5b9c688e9e  Geez, are you forgetful!  We've already discus...   \n",
      "1    c03f72fd8f8bf54f  Carioca RFA \\n\\nThanks for your support on my ...   \n",
      "2    9e5b8e8fc1ff2e84  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...   \n",
      "3    5332799e706665a6  Pseudoscience category? \\n\\nI'm assuming that ...   \n",
      "4    dfa7d8f0b4366680  (and if such phrase exists, it would be provid...   \n",
      "..                ...                                                ...   \n",
      "995  c8b3828a01b69eff  2006 (UTC)\\n\\n Not that any of the rest of us ...   \n",
      "996  fd7dd2198d5b0d47  \"\\n\\n Yay, let's all do the Pedantic Semantics...   \n",
      "997  a891a275a471d4d8               no am not how am I supposed to Know?   \n",
      "998  5217403575e87ab2  If you guys really discuss napoleon you need t...   \n",
      "999  d6f89bfcee733ebe  \"\\n please consider this as a personal attack ...   \n",
      "\n",
      "     toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0        0             0        0       0       0              0  \n",
      "1        0             0        0       0       0              0  \n",
      "2        0             0        0       0       0              0  \n",
      "3        0             0        0       0       0              0  \n",
      "4        0             0        0       0       0              0  \n",
      "..     ...           ...      ...     ...     ...            ...  \n",
      "995      0             0        0       0       0              0  \n",
      "996      0             0        0       0       0              0  \n",
      "997      0             0        0       0       0              0  \n",
      "998      1             0        1       0       1              1  \n",
      "999      0             0        0       0       0              0  \n",
      "\n",
      "[1000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 8)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BertModel and  BertTokenizer 'distilbert-base-uncased' \n",
    "or \n",
    "DistilBertModel and DistilBertTokenizer 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = transformers.DistilBertModel\n",
    "tokenizer_class = transformers.DistilBertTokenizer\n",
    "pretrained_weights='distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "bert_model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(df, max_seq):\n",
    "    return [\n",
    "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.comment_text.values\n",
    "    ]\n",
    "\n",
    "\n",
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
    "\n",
    "\n",
    "def tokenize_and_pad_text(df, max_seq):\n",
    "    tokenized_text = tokenize_text(df, max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text,dtype=torch.long)\n",
    "\n",
    "\n",
    "def targets_to_tensor(df, target_columns):\n",
    "    return torch.tensor(df[target_columns].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = tokenize_and_pad_text(df_train, max_seq)\n",
    "val_indices = tokenize_and_pad_text(df_val, max_seq)\n",
    "test_indices = tokenize_and_pad_text(df_test, max_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 20277,  2480,  ...,     0,     0,     0],\n",
       "        [  101,  2482,  3695,  ...,     0,     0,     0],\n",
       "        [  101,  1000,  5798,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2053,  2572,  ...,     0,     0,     0],\n",
       "        [  101,  2065,  2017,  ...,     0,     0,     0],\n",
       "        [  101,  1000,  3531,  ...,  2013,  2033,  2097]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_train = bert_model(train_indices)[0]  # Models outputs are tuples\n",
    "    x_val = bert_model(val_indices)[0]\n",
    "    x_test = bert_model(test_indices)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = targets_to_tensor(df_train, target_columns)\n",
    "y_val = targets_to_tensor(df_val, target_columns)\n",
    "y_test = targets_to_tensor(df_test, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0727,  0.1309, -0.3334,  ..., -0.0015,  0.7520,  0.2843],\n",
       "        [ 1.2851,  0.5124,  0.9945,  ...,  0.3025,  0.6214, -0.4508],\n",
       "        [ 0.2423,  0.1599,  0.8900,  ...,  0.5063,  0.7130,  0.1000],\n",
       "        ...,\n",
       "        [ 0.3247, -0.1526,  0.4717,  ..., -0.1131,  0.4675, -0.3168],\n",
       "        [ 0.3465, -0.1225,  0.4829,  ..., -0.0879,  0.4579, -0.3824],\n",
       "        [ 0.3402, -0.0146,  0.4141,  ...,  0.0043,  0.3367, -0.4468]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 768])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KimCNN(nn.Module):\n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
    "        super(KimCNN, self).__init__()\n",
    "\n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        self.static = static\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.static:\n",
    "            x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        output = self.sigmoid(logit)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_num = x_train.shape[1]\n",
    "embed_dim = x_train.shape[2]\n",
    "class_num = y_train.shape[1]\n",
    "kernel_num = 3\n",
    "kernel_sizes = [2, 3, 4]\n",
    "dropout = 0.5\n",
    "static = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KimCNN(\n",
    "    embed_num=embed_num,\n",
    "    embed_dim=embed_dim,\n",
    "    class_num=class_num,\n",
    "    kernel_num=kernel_num,\n",
    "    kernel_sizes=kernel_sizes,\n",
    "    dropout=dropout,\n",
    "    static=static,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 10\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data(x, y, batch_size):\n",
    "    i, batch = 0, 0\n",
    "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
    "        x_batch = x[i : i + batch_size]\n",
    "        y_batch = y[i : i + batch_size]\n",
    "        yield x_batch, y_batch, batch\n",
    "    if i + batch_size < len(x):\n",
    "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
    "    if batch == 0:\n",
    "        yield x, y, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train loss: 0.51. Validation loss: 0.29. Elapsed time: 2.63s.\n",
      "Epoch 2 Train loss: 0.37. Validation loss: 0.19. Elapsed time: 2.30s.\n",
      "Epoch 3 Train loss: 0.29. Validation loss: 0.15. Elapsed time: 2.28s.\n",
      "Epoch 4 Train loss: 0.25. Validation loss: 0.13. Elapsed time: 2.25s.\n",
      "Epoch 5 Train loss: 0.24. Validation loss: 0.12. Elapsed time: 2.27s.\n",
      "Epoch 6 Train loss: 0.19. Validation loss: 0.13. Elapsed time: 2.31s.\n",
      "Epoch 7 Train loss: 0.19. Validation loss: 0.12. Elapsed time: 2.26s.\n",
      "Epoch 8 Train loss: 0.18. Validation loss: 0.11. Elapsed time: 2.33s.\n",
      "Epoch 9 Train loss: 0.18. Validation loss: 0.11. Elapsed time: 2.36s.\n",
      "Epoch 10 Train loss: 0.16. Validation loss: 0.11. Elapsed time: 2.29s.\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train(True)\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
    "        y_pred = model(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= batch\n",
    "    train_losses.append(train_loss)\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    model.eval() # disable dropout for deterministic output\n",
    "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "        val_loss, batch = 0, 1\n",
    "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
    "            y_pred = model(x_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= batch\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    print(\n",
    "        \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\"\n",
    "        % (epoch + 1, train_losses[-1], val_losses[-1], elapsed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Losses')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # disable dropout for deterministic output\n",
    "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "    y_preds = []\n",
    "    batch = 0\n",
    "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, batch_size):\n",
    "        y_pred = model(x_batch)\n",
    "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
    "    y_preds_np = np.array(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.10594016e-02, 6.56805281e-03, 4.89265174e-02, 6.89648651e-03,\n",
       "        3.40272412e-02, 1.10260230e-02],\n",
       "       [5.32477140e-01, 3.73149887e-02, 2.41502866e-01, 1.92642268e-02,\n",
       "        2.66050220e-01, 5.63451648e-02],\n",
       "       [3.03845899e-03, 4.91465153e-06, 4.52160864e-04, 3.67023858e-06,\n",
       "        2.97099818e-04, 1.09382272e-05],\n",
       "       ...,\n",
       "       [1.37184933e-02, 1.01682468e-04, 3.44740925e-03, 1.13912334e-04,\n",
       "        2.25724140e-03, 2.16707631e-04],\n",
       "       [2.73415050e-03, 6.99092561e-06, 4.13249334e-04, 5.06103515e-06,\n",
       "        2.87130155e-04, 1.27459207e-05],\n",
       "       [1.92395039e-02, 8.76668637e-05, 4.09173686e-03, 9.18152800e-05,\n",
       "        2.74606375e-03, 1.80518065e-04]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = df_test[target_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 6), dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_np[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-68b3641e81d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mauc_scores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    353\u001b[0m     return _average_binary_score(\n\u001b[1;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0my_score_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnot_average_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         score[c] = binary_metric(y_true_c, y_score_c,\n\u001b[0;32m--> 119\u001b[0;31m                                  sample_weight=score_weight)\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# Average the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    324\u001b[0m                              \"is not defined in that case.\")\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
    "df_accuracy = pd.DataFrame({\"label\": target_columns, \"auc\": auc_scores})\n",
    "df_accuracy.sort_values('auc')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels = df_train[target_columns].sum().sum()\n",
    "positive_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels = df_train[target_columns].count().sum()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036166666666666666"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_labels/all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_targets = df_test[target_columns]\n",
    "df_pred_targets = pd.DataFrame(y_preds_np.round(), columns=target_columns, dtype=int)\n",
    "df_sanity = df_test_targets.join(df_pred_targets, how='inner', rsuffix='_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>toxic_pred</th>\n",
       "      <th>severe_toxic_pred</th>\n",
       "      <th>obscene_pred</th>\n",
       "      <th>threat_pred</th>\n",
       "      <th>insult_pred</th>\n",
       "      <th>identity_hate_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate  toxic_pred  \\\n",
       "0        0             0        0       0       0              0           0   \n",
       "1        0             0        0       0       0              0           1   \n",
       "2        0             0        0       0       0              0           0   \n",
       "3        0             0        0       0       0              0           0   \n",
       "4        0             0        0       0       0              0           0   \n",
       "..     ...           ...      ...     ...     ...            ...         ...   \n",
       "195      0             0        0       0       0              0           0   \n",
       "196      0             0        0       0       0              0           0   \n",
       "197      0             0        0       0       0              0           0   \n",
       "198      0             0        0       0       0              0           0   \n",
       "199      0             0        0       0       0              0           0   \n",
       "\n",
       "     severe_toxic_pred  obscene_pred  threat_pred  insult_pred  \\\n",
       "0                    0             0            0            0   \n",
       "1                    0             0            0            0   \n",
       "2                    0             0            0            0   \n",
       "3                    0             0            0            0   \n",
       "4                    0             0            0            0   \n",
       "..                 ...           ...          ...          ...   \n",
       "195                  0             0            0            0   \n",
       "196                  0             0            0            0   \n",
       "197                  0             0            0            0   \n",
       "198                  0             0            0            0   \n",
       "199                  0             0            0            0   \n",
       "\n",
       "     identity_hate_pred  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "..                  ...  \n",
       "195                   0  \n",
       "196                   0  \n",
       "197                   0  \n",
       "198                   0  \n",
       "199                   0  \n",
       "\n",
       "[200 rows x 12 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            18\n",
       "severe_toxic      1\n",
       "obscene           6\n",
       "threat            0\n",
       "insult            6\n",
       "identity_hate     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            5\n",
       "severe_toxic     0\n",
       "obscene          2\n",
       "threat           0\n",
       "insult           2\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_targets.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxic_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     toxic  toxic_pred\n",
       "7        1           1\n",
       "14       1           0\n",
       "16       1           1\n",
       "22       1           0\n",
       "40       1           0\n",
       "52       1           0\n",
       "58       1           0\n",
       "80       1           0\n",
       "84       1           0\n",
       "100      1           0\n",
       "113      1           1\n",
       "121      1           0\n",
       "126      1           0\n",
       "127      1           0\n",
       "131      1           1\n",
       "139      1           0\n",
       "170      1           0\n",
       "182      1           0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanity[df_sanity.toxic > 0][['toxic', 'toxic_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
